{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a836b89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded ML file: admissionDx.csv.gz | Shape: (7578, 6)\n",
      "✅ Loaded ML file: admissiondrug.csv.gz | Shape: (7417, 14)\n",
      "✅ Loaded ML file: allergy.csv.gz | Shape: (2475, 13)\n",
      "✅ Loaded ML file: apacheApsVar.csv.gz | Shape: (2205, 26)\n",
      "✅ Loaded ML file: apachePatientResult.csv.gz | Shape: (3676, 23)\n",
      "✅ Loaded ML file: apachePredVar.csv.gz | Shape: (2205, 51)\n",
      "✅ Loaded ML file: carePlanCareProvider.csv.gz | Shape: (5627, 8)\n",
      "✅ Loaded ML file: carePlanGeneral.csv.gz | Shape: (33148, 6)\n",
      "✅ Loaded ML file: carePlanGoal.csv.gz | Shape: (3633, 7)\n",
      "✅ Loaded ML file: carePlanInfectiousDisease.csv.gz | Shape: (112, 8)\n",
      "✅ Loaded ML file: customLab.csv.gz | Shape: (30, 7)\n",
      "✅ Loaded ML file: diagnosis.csv.gz | Shape: (24978, 7)\n",
      "✅ Loaded ML file: hospital.csv.gz | Shape: (186, 4)\n",
      "✅ Loaded ML file: infusiondrug.csv.gz | Shape: (38256, 9)\n",
      "✅ Loaded ML file: intakeOutput.csv.gz | Shape: (100466, 12)\n",
      "✅ Loaded ML file: lab.csv.gz | Shape: (434660, 10)\n",
      "✅ Loaded ML file: medication.csv.gz | Shape: (75604, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_15436\\1253520010.py:32: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ml_data[file] = pd.read_csv(path, compression='gzip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded ML file: microLab.csv.gz | Shape: (342, 7)\n",
      "✅ Loaded ML file: nurseAssessment.csv.gz | Shape: (91589, 8)\n",
      "✅ Loaded ML file: nurseCare.csv.gz | Shape: (42080, 8)\n",
      "✅ Loaded ML file: nurseCharting.csv.gz | Shape: (1477163, 8)\n",
      "✅ Loaded ML file: pastHistory.csv.gz | Shape: (12109, 8)\n",
      "✅ Loaded ML file: patient.csv.gz | Shape: (2520, 29)\n",
      "✅ Loaded ML file: physicalExam.csv.gz | Shape: (84058, 6)\n",
      "✅ Loaded ML file: respiratoryCare.csv.gz | Shape: (5436, 34)\n",
      "✅ Loaded ML file: respiratoryCharting.csv.gz | Shape: (176089, 7)\n",
      "✅ Loaded ML file: treatment.csv.gz | Shape: (38290, 5)\n",
      "✅ Loaded ML file: vitalPeriodic.csv.gz | Shape: (1634960, 19)\n",
      "✅ Loaded NLP file: note.csv.gz | Shape: (24758, 8)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Change this to your actual folder path\n",
    "data_folder = r\"C:\\Users\\asus\\Downloads\\health api\"\n",
    "\n",
    "# ML and NLP file lists\n",
    "ml_files = [\n",
    "    'admissionDx.csv.gz', 'admissiondrug.csv.gz', 'allergy.csv.gz', 'apacheApsVar.csv.gz',\n",
    "    'apachePatientResult.csv.gz', 'apachePredVar.csv.gz', 'carePlanCareProvider.csv.gz',\n",
    "    'carePlanGeneral.csv.gz', 'carePlanGoal.csv.gz',\n",
    "    'carePlanInfectiousDisease.csv.gz', 'customLab.csv.gz', 'diagnosis.csv.gz',\n",
    "    'hospital.csv.gz', 'infusiondrug.csv.gz', 'intakeOutput.csv.gz', 'lab.csv.gz',\n",
    "    'medication.csv.gz', 'microLab.csv.gz', 'nurseAssessment.csv.gz', 'nurseCare.csv.gz',\n",
    "    'nurseCharting.csv.gz', 'pastHistory.csv.gz', 'patient.csv.gz', 'physicalExam.csv.gz',\n",
    "    'respiratoryCare.csv.gz', 'respiratoryCharting.csv.gz', 'treatment.csv.gz',\n",
    "     'vitalPeriodic.csv.gz'\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "nlp_files = ['note.csv.gz']\n",
    "\n",
    "# Dictionaries to store data\n",
    "ml_data = {}\n",
    "nlp_data = {}\n",
    "\n",
    "# Load ML files\n",
    "for file in ml_files:\n",
    "    path = os.path.join(data_folder, file)\n",
    "    if os.path.exists(path):\n",
    "        ml_data[file] = pd.read_csv(path, compression='gzip')\n",
    "        print(f\"✅ Loaded ML file: {file} | Shape: {ml_data[file].shape}\")\n",
    "    else:\n",
    "        print(f\" Missing ML file: {file}\")\n",
    "        \n",
    "# Load NLP files\n",
    "for file in nlp_files:\n",
    "    path = os.path.join(data_folder, file)\n",
    "    if os.path.exists(path):\n",
    "        nlp_data[file] = pd.read_csv(path, compression='gzip')\n",
    "        print(f\"✅ Loaded NLP file: {file} | Shape: {nlp_data[file].shape}\")\n",
    "    else:\n",
    "        print(f\"❌ Missing NLP file: {file}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0d8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "admission_dx = ml_data[ 'admissionDx.csv.gz']\n",
    "admission_drug = ml_data['admissiondrug.csv.gz'] \n",
    "allergy = ml_data['allergy.csv.gz']\n",
    "apache_aps_var = ml_data['apacheApsVar.csv.gz']     \n",
    "apache_patient_result = ml_data['apachePatientResult.csv.gz']\n",
    "apache_pred_var = ml_data['apachePredVar.csv.gz']\n",
    "care_plan_care_provider = ml_data['carePlanCareProvider.csv.gz']\n",
    "care_plan_general = ml_data['carePlanGeneral.csv.gz']\n",
    "care_plan_goal = ml_data['carePlanGoal.csv.gz']\n",
    "care_plan_infectious_disease = ml_data['carePlanInfectiousDisease.csv.gz']     \n",
    "custom_lab = ml_data['customLab.csv.gz']\n",
    "diagnosis = ml_data['diagnosis.csv.gz']\n",
    "hospital = ml_data['hospital.csv.gz']\n",
    "infusion_drug = ml_data['infusiondrug.csv.gz']\n",
    "intake_output = ml_data['intakeOutput.csv.gz']\n",
    "lab = ml_data['lab.csv.gz']\n",
    "medication = ml_data['medication.csv.gz']\n",
    "micro_lab = ml_data['microLab.csv.gz']\n",
    "nurse_assessment = ml_data['nurseAssessment.csv.gz']\n",
    "nurse_care = ml_data['nurseCare.csv.gz']\n",
    "nurse_charting = ml_data['nurseCharting.csv.gz']\n",
    "past_history = ml_data['pastHistory.csv.gz']\n",
    "patient = ml_data['patient.csv.gz']\n",
    "physical_exam = ml_data['physicalExam.csv.gz']\n",
    "respiratory_care = ml_data['respiratoryCare.csv.gz']\n",
    "respiratory_charting = ml_data['respiratoryCharting.csv.gz']\n",
    "treatment = ml_data['treatment.csv.gz']\n",
    "vital_periodic = ml_data['vitalPeriodic.csv.gz']\n",
    "    \n",
    "note = nlp_data['note.csv.gz']     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ada7c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vitalperiodicid', 'patientunitstayid', 'observationoffset',\n",
      "       'temperature', 'sao2', 'heartrate', 'respiration', 'cvp', 'etco2',\n",
      "       'systemicsystolic', 'systemicdiastolic', 'systemicmean', 'pasystolic',\n",
      "       'padiastolic', 'pamean', 'st1', 'st2', 'st3', 'icp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vital_periodic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc858dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all physionet tables into a dictionary\n",
    "data_dict = {\n",
    "    \"admission_dx\": ml_data['admissionDx.csv.gz'],\n",
    "    \"admission_drug\": ml_data['admissiondrug.csv.gz'],\n",
    "    \"allergy\": ml_data['allergy.csv.gz'],\n",
    "    \"apache_aps_var\": ml_data['apacheApsVar.csv.gz'],\n",
    "    \"apache_patient_result\": ml_data['apachePatientResult.csv.gz'],\n",
    "    \"apache_pred_var\": ml_data['apachePredVar.csv.gz'],\n",
    "    \"care_plan_care_provider\": ml_data['carePlanCareProvider.csv.gz'],\n",
    "    \"care_plan_general\": ml_data['carePlanGeneral.csv.gz'],\n",
    "    \"care_plan_goal\": ml_data['carePlanGoal.csv.gz'],\n",
    "    \"care_plan_infectious_disease\": ml_data['carePlanInfectiousDisease.csv.gz'],\n",
    "    \"custom_lab\": ml_data['customLab.csv.gz'],\n",
    "    \"diagnosis\": ml_data['diagnosis.csv.gz'],\n",
    "    \"hospital\": ml_data['hospital.csv.gz'],\n",
    "    \"infusion_drug\": ml_data['infusiondrug.csv.gz'],\n",
    "    \"intake_output\": ml_data['intakeOutput.csv.gz'],\n",
    "    \"lab\": ml_data['lab.csv.gz'],\n",
    "    \"medication\": ml_data['medication.csv.gz'],\n",
    "    \"micro_lab\": ml_data['microLab.csv.gz'],\n",
    "    \"nurse_assessment\": ml_data['nurseAssessment.csv.gz'],\n",
    "    \"nurse_care\": ml_data['nurseCare.csv.gz'],\n",
    "    \"nurse_charting\": ml_data['nurseCharting.csv.gz'],\n",
    "    \"past_history\": ml_data['pastHistory.csv.gz'],\n",
    "    \"patient\": ml_data['patient.csv.gz'],\n",
    "    \"physical_exam\": ml_data['physicalExam.csv.gz'],\n",
    "    \"respiratory_care\": ml_data['respiratoryCare.csv.gz'],\n",
    "    \"respiratory_charting\": ml_data['respiratoryCharting.csv.gz'],\n",
    "    \"treatment\": ml_data['treatment.csv.gz'],\n",
    "    \"vital_periodic\": ml_data['vitalPeriodic.csv.gz'],\n",
    "    \"note\": nlp_data['note.csv.gz']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df22bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984d52ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  admission_dx: (7578, 6)\n",
      "   admissiondxid  patientunitstayid  admitdxenteredoffset  \\\n",
      "0        7351978            2900423                   162   \n",
      "1        7351977            2900423                   162   \n",
      "\n",
      "                                         admitdxpath     admitdxname  \\\n",
      "0  admission diagnosis|Non-operative Organ System...  Cardiovascular   \n",
      "1  admission diagnosis|Was the patient admitted f...              No   \n",
      "\n",
      "      admitdxtext  \n",
      "0  Cardiovascular  \n",
      "1              No   \n",
      "\n",
      "  admission_drug: (7417, 14)\n",
      "   admissiondrugid  patientunitstayid  drugoffset  drugenteredoffset  \\\n",
      "0          1373386             281479         420                444   \n",
      "1          1917810             281479          24                 31   \n",
      "\n",
      "     drugnotetype specialtytype       usertype  rxincluded  writtenineicu  \\\n",
      "0  Daily Progress   eCM Primary  THC Physician       False           True   \n",
      "1       Admission   eCM Primary      THC Nurse        True           True   \n",
      "\n",
      "                                            drugname  drugdosage drugunit  \\\n",
      "0  NOVOLOG                                       ...         0.0            \n",
      "1  NOVOLOG                                       ...         0.0            \n",
      "\n",
      "  drugadmitfrequency  drughiclseqno  \n",
      "0                             20769  \n",
      "1                             20769   \n",
      "\n",
      "  allergy: (2475, 13)\n",
      "   allergyid  patientunitstayid  allergyoffset  allergyenteredoffset  \\\n",
      "0     357144             243097           2549                  2552   \n",
      "1     442253             243097           1288                  1294   \n",
      "\n",
      "          allergynotetype specialtytype   usertype  rxincluded  writtenineicu  \\\n",
      "0  Comprehensive Progress   eCM Primary  THC Nurse        True           True   \n",
      "1  Comprehensive Progress   eCM Primary  THC Nurse        True           True   \n",
      "\n",
      "            drugname allergytype        allergyname  drughiclseqno  \n",
      "0                NaN    Non Drug        penicillins            NaN  \n",
      "1  CODEINE PHOSPHATE        Drug  CODEINE PHOSPHATE         1721.0   \n",
      "\n",
      "  apache_aps_var: (2205, 26)\n",
      "   apacheapsvarid  patientunitstayid  intubated  vent  dialysis  eyes  motor  \\\n",
      "0           92788             141765          0     0         0     4      6   \n",
      "1            8893             143870          0     0         0     4      6   \n",
      "\n",
      "   verbal  meds  urine  ...   ph  hematocrit  creatinine  albumin  pao2  pco2  \\\n",
      "0       5     0   -1.0  ... -1.0        37.8        1.04     -1.0  -1.0  -1.0   \n",
      "1       5     0   -1.0  ... -1.0        34.1        1.14     -1.0  -1.0  -1.0   \n",
      "\n",
      "    bun  glucose  bilirubin  fio2  \n",
      "0  28.0       61       -1.0    -1  \n",
      "1  14.0      140       -1.0    -1  \n",
      "\n",
      "[2 rows x 26 columns] \n",
      "\n",
      "  apache_patient_result: (3676, 23)\n",
      "   apachepatientresultsid  patientunitstayid physicianspeciality  \\\n",
      "0                   31917             141765         hospitalist   \n",
      "1                   31918             141765         hospitalist   \n",
      "\n",
      "  physicianinterventioncategory  acutephysiologyscore  apachescore  \\\n",
      "0                       Unknown                    23           47   \n",
      "1                       Unknown                    23           47   \n",
      "\n",
      "  apacheversion  predictedicumortality actualicumortality  predictediculos  \\\n",
      "0            IV               0.008247              ALIVE         0.722231   \n",
      "1           IVa               0.012311              ALIVE         1.374807   \n",
      "\n",
      "   ...  predictedhospitallos  actualhospitallos preopmi  preopcardiaccath  \\\n",
      "0  ...              2.881710             1.8222       0                 0   \n",
      "1  ...              3.173925             1.8222       0                 0   \n",
      "\n",
      "   ptcawithin24h  unabridgedunitlos  unabridgedhosplos  actualventdays  \\\n",
      "0              0             1.5625             1.8222             NaN   \n",
      "1              0             1.5625             1.8222             NaN   \n",
      "\n",
      "   predventdays  unabridgedactualventdays  \n",
      "0           NaN                       NaN  \n",
      "1           NaN                       NaN  \n",
      "\n",
      "[2 rows x 23 columns] \n",
      "\n",
      "  apache_pred_var: (2205, 51)\n",
      "   apachepredvarid  patientunitstayid  sicuday  saps3day1  saps3today  \\\n",
      "0             4004             141765        1          0           0   \n",
      "1             8047             143870        1          0           0   \n",
      "\n",
      "   saps3yesterday  gender  teachtype  region  bedcount  ...  creatinine  \\\n",
      "0               0       1          0       3        12  ...        1.04   \n",
      "1               0       0          0       3        14  ...        1.14   \n",
      "\n",
      "   dischargelocation  visitnumber  amilocation  day1meds  day1verbal  \\\n",
      "0                  4            1           -1         0           5   \n",
      "1                  4            1           -1         0           5   \n",
      "\n",
      "   day1motor day1eyes  day1pao2  day1fio2  \n",
      "0          6        4      -1.0        -1  \n",
      "1          6        4      -1.0        -1  \n",
      "\n",
      "[2 rows x 51 columns] \n",
      "\n",
      "  care_plan_care_provider: (5627, 8)\n",
      "   cplcareprovderid  patientunitstayid  careprovidersaveoffset  providertype  \\\n",
      "0           1124435             149713                      11           NaN   \n",
      "1           1196330             157016                       2           NaN   \n",
      "\n",
      "               specialty interventioncategory managingphysician  \\\n",
      "0        family practice                    I          Managing   \n",
      "1  obstetrics/gynecology                    I          Managing   \n",
      "\n",
      "   activeupondischarge  \n",
      "0                 True  \n",
      "1                 True   \n",
      "\n",
      "  care_plan_general: (33148, 6)\n",
      "   cplgeneralid  patientunitstayid  activeupondischarge  cplitemoffset  \\\n",
      "0       3665765             174826                 True             49   \n",
      "1       3608330             174826                 True             49   \n",
      "\n",
      "          cplgroup            cplitemvalue  \n",
      "0      Ventilation  Spontaneous - adequate  \n",
      "1  Care Limitation            Full therapy   \n",
      "\n",
      "  care_plan_goal: (3633, 7)\n",
      "   cplgoalid  patientunitstayid  cplgoaloffset cplgoalcategory  \\\n",
      "0    2287240            1318254            800  Infection/Labs   \n",
      "1    2287241            1318254            800  Infection/Labs   \n",
      "\n",
      "          cplgoalvalue cplgoalstatus  activeupondischarge  \n",
      "0  Normal electrolytes        Active                 True  \n",
      "1    Absence of sepsis        Active                 True   \n",
      "\n",
      "  care_plan_infectious_disease: (112, 8)\n",
      "   cplinfectid  patientunitstayid  activeupondischarge  \\\n",
      "0         3329             249328                 True   \n",
      "1         3234             260860                False   \n",
      "\n",
      "   cplinfectdiseaseoffset infectdiseasesite infectdiseaseassessment  \\\n",
      "0                    1153     Urinary tract      Definite infection   \n",
      "1                    1451     Urinary tract      Definite infection   \n",
      "\n",
      "  responsetotherapy treatment  \n",
      "0               NaN       NaN  \n",
      "1               NaN       NaN   \n",
      "\n",
      "  custom_lab: (30, 7)\n",
      "   customlabid  patientunitstayid  labotheroffset  labothertypeid  \\\n",
      "0        25451             243999              45               1   \n",
      "1        25450             243999             450               1   \n",
      "\n",
      "           labothername  labotherresult labothervaluetext  \n",
      "0  Creatinine w Est GFR            51.0                51  \n",
      "1                   GFR             NaN               >60   \n",
      "\n",
      "  diagnosis: (24978, 7)\n",
      "   diagnosisid  patientunitstayid  activeupondischarge  diagnosisoffset  \\\n",
      "0      7607199             346380                False             5028   \n",
      "1      7570429             346380                False              685   \n",
      "\n",
      "                                     diagnosisstring        icd9code  \\\n",
      "0  cardiovascular|ventricular disorders|hypertension      401.9, I10   \n",
      "1  neurologic|altered mental status / pain|change...  780.09, R41.82   \n",
      "\n",
      "  diagnosispriority  \n",
      "0             Other  \n",
      "1             Major   \n",
      "\n",
      "  hospital: (186, 4)\n",
      "   hospitalid numbedscategory teachingstatus   region\n",
      "0          56            <100              f  Midwest\n",
      "1          58       100 - 249              f  Midwest \n",
      "\n",
      "  infusion_drug: (38256, 9)\n",
      "   infusiondrugid  patientunitstayid  infusionoffset  \\\n",
      "0        40215081            1461035             768   \n",
      "1        38752780            1461035             648   \n",
      "\n",
      "                         drugname drugrate  infusionrate  drugamount  \\\n",
      "0  Volume (mL) Magnesium  (ml/hr)       25           NaN         NaN   \n",
      "1  Volume (mL) Magnesium  (ml/hr)       25           NaN         NaN   \n",
      "\n",
      "   volumeoffluid  patientweight  \n",
      "0            NaN            NaN  \n",
      "1            NaN            NaN   \n",
      "\n",
      "  intake_output: (100466, 12)\n",
      "   intakeoutputid  patientunitstayid  intakeoutputoffset  intaketotal  \\\n",
      "0         9314532             147307                -394          0.0   \n",
      "1         9314533             147307                -394          0.0   \n",
      "\n",
      "   outputtotal  dialysistotal  nettotal  intakeoutputentryoffset  \\\n",
      "0          0.0            0.0       0.0                     -394   \n",
      "1          0.0            0.0       0.0                     -394   \n",
      "\n",
      "                                            cellpath        celllabel  \\\n",
      "0  flowsheet|Flowsheet Cell Labels|I&O|Weight|Bod...  Bodyweight (lb)   \n",
      "1  flowsheet|Flowsheet Cell Labels|I&O|Weight|Bod...  Bodyweight (kg)   \n",
      "\n",
      "   cellvaluenumeric  cellvaluetext  \n",
      "0             159.8          159.8  \n",
      "1              72.5           72.5   \n",
      "\n",
      "  lab: (434660, 10)\n",
      "       labid  patientunitstayid  labresultoffset  labtypeid           labname  \\\n",
      "0  437880563            1754323             -647          3               Hct   \n",
      "1  437880572            1754323             -647          3  platelets x 1000   \n",
      "\n",
      "   labresult labresulttext labmeasurenamesystem labmeasurenameinterface  \\\n",
      "0       38.3          38.3                    %                       %   \n",
      "1      181.0           181                K/mcL                 k/mm cu   \n",
      "\n",
      "   labresultrevisedoffset  \n",
      "0                    -631  \n",
      "1                    -631   \n",
      "\n",
      "  medication: (75604, 15)\n",
      "   medicationid  patientunitstayid  drugorderoffset  drugstartoffset  \\\n",
      "0       7278819             141765              134             1396   \n",
      "1       9726266             141765                1             -188   \n",
      "\n",
      "  drugivadmixture drugordercancelled  \\\n",
      "0              No                 No   \n",
      "1              No                 No   \n",
      "\n",
      "                                      drugname  drughiclseqno dosage  \\\n",
      "0                 WARFARIN SODIUM 5 MG PO TABS         2812.0    5 3   \n",
      "1  5 ML VIAL : DILTIAZEM HCL 25 MG/5ML IV SOLN          182.0   15 3   \n",
      "\n",
      "  routeadmin frequency loadingdose  prn  drugstopoffset  gtc  \n",
      "0         PO       NaN         NaN   No            2739    0  \n",
      "1         IV  Once PRN         NaN  Yes             171   38   \n",
      "\n",
      "  micro_lab: (342, 7)\n",
      "   microlabid  patientunitstayid  culturetakenoffset           culturesite  \\\n",
      "0      840759            2597777                1343  Sputum, Expectorated   \n",
      "1      840628            2597777                2723  Sputum, Expectorated   \n",
      "\n",
      "      organism antibiotic sensitivitylevel  \n",
      "0  mixed flora        NaN              NaN  \n",
      "1  mixed flora        NaN              NaN   \n",
      "\n",
      "  nurse_assessment: (91589, 8)\n",
      "   nurseassessid  patientunitstayid  nurseassessoffset  \\\n",
      "0       57436984            1054428              13791   \n",
      "1       57483728            1036759               4075   \n",
      "\n",
      "   nurseassessentryoffset                                  cellattributepath  \\\n",
      "0                   13819  flowsheet|Flowsheet Cell Labels|Nursing Assess...   \n",
      "1                    4076  flowsheet|Flowsheet Cell Labels|Nursing Assess...   \n",
      "\n",
      "    celllabel cellattribute cellattributevalue  \n",
      "0       Edema         Edema        generalized  \n",
      "1  Secretions    Secretions            minimal   \n",
      "\n",
      "  nurse_care: (42080, 8)\n",
      "   nursecareid  patientunitstayid     celllabel  nursecareoffset  \\\n",
      "0     20977673            1014000  Hygiene/ADLs             2151   \n",
      "1     20977674            1014000  Hygiene/ADLs             2151   \n",
      "\n",
      "   nursecareentryoffset                                  cellattributepath  \\\n",
      "0                  2138  flowsheet|Flowsheet Cell Labels|Nursing Care|H...   \n",
      "1                  2138  flowsheet|Flowsheet Cell Labels|Nursing Care|H...   \n",
      "\n",
      "  cellattribute cellattributevalue  \n",
      "0  Hygiene/ADLs        ADLs assist  \n",
      "1  Hygiene/ADLs          oral care   \n",
      "\n",
      "  nurse_charting: (1477163, 8)\n",
      "   nursingchartid  patientunitstayid  nursingchartoffset  \\\n",
      "0       189336686             143870                 -67   \n",
      "1       187848155             143870                 239   \n",
      "\n",
      "   nursingchartentryoffset          nursingchartcelltypecat  \\\n",
      "0                      -67  Other Vital Signs and Infusions   \n",
      "1                      239  Other Vital Signs and Infusions   \n",
      "\n",
      "        nursingchartcelltypevallabel nursingchartcelltypevalname  \\\n",
      "0  Eye, Ear, Nose, Throat Assessment                       Value   \n",
      "1        Gastrointestinal Assessment                       Value   \n",
      "\n",
      "  nursingchartvalue  \n",
      "0               WDL  \n",
      "1                 X   \n",
      "\n",
      "  past_history: (12109, 8)\n",
      "   pasthistoryid  patientunitstayid  pasthistoryoffset  \\\n",
      "0         990803             141765                  7   \n",
      "1         970059             143870                  4   \n",
      "\n",
      "   pasthistoryenteredoffset     pasthistorynotetype  \\\n",
      "0                        12  Comprehensive Progress   \n",
      "1                        10  Comprehensive Progress   \n",
      "\n",
      "                                     pasthistorypath    pasthistoryvalue  \\\n",
      "0  notes/Progress Notes/Past History/Past History...  No Health Problems   \n",
      "1  notes/Progress Notes/Past History/Past History...  No Health Problems   \n",
      "\n",
      "  pasthistoryvaluetext  \n",
      "0     NoHealthProblems  \n",
      "1     NoHealthProblems   \n",
      "\n",
      "  patient: (2520, 29)\n",
      "   patientunitstayid  patienthealthsystemstayid  gender age  ethnicity  \\\n",
      "0             141764                     129391  Female  87  Caucasian   \n",
      "1             141765                     129391  Female  87  Caucasian   \n",
      "\n",
      "   hospitalid  wardid                              apacheadmissiondx  \\\n",
      "0          59      91                                            NaN   \n",
      "1          59      91  Rhythm disturbance (atrial, supraventricular)   \n",
      "\n",
      "   admissionheight hospitaladmittime24  ...       unitadmitsource  \\\n",
      "0            157.5            23:36:00  ...            ICU to SDU   \n",
      "1            157.5            23:36:00  ...  Emergency Department   \n",
      "\n",
      "  unitvisitnumber    unitstaytype admissionweight  dischargeweight  \\\n",
      "0               2  stepdown/other             NaN              NaN   \n",
      "1               1           admit            46.5             45.0   \n",
      "\n",
      "  unitdischargetime24 unitdischargeoffset unitdischargelocation  \\\n",
      "0            18:58:00                 344                  Home   \n",
      "1            13:14:00                2250  Step-Down Unit (SDU)   \n",
      "\n",
      "  unitdischargestatus uniquepid  \n",
      "0               Alive  002-1039  \n",
      "1               Alive  002-1039  \n",
      "\n",
      "[2 rows x 29 columns] \n",
      "\n",
      "  physical_exam: (84058, 6)\n",
      "   physicalexamid  patientunitstayid  physicalexamoffset  \\\n",
      "0         5276231             157427                   1   \n",
      "1         5276232             157427                   1   \n",
      "\n",
      "                                    physicalexampath       physicalexamvalue  \\\n",
      "0  notes/Progress Notes/Physical Exam/Physical Ex...                  scored   \n",
      "1  notes/Progress Notes/Physical Exam/Physical Ex...  Performed - Structured   \n",
      "\n",
      "         physicalexamtext  \n",
      "0                  scored  \n",
      "1  Performed - Structured   \n",
      "\n",
      "  respiratory_care: (5436, 34)\n",
      "   respcareid  patientunitstayid  respcarestatusoffset  currenthistoryseqnum  \\\n",
      "0      564013             147784                  1188                     2   \n",
      "1      564012             147784                   -61                     1   \n",
      "\n",
      "  airwaytype  airwaysize airwayposition  cuffpressure  ventstartoffset  \\\n",
      "0        NaN         NaN            NaN           NaN                0   \n",
      "1        NaN         NaN            NaN           NaN             -361   \n",
      "\n",
      "   ventendoffset  ...  peeplimit  cpaplimit setapneainterval  setapneatv  \\\n",
      "0              0  ...        NaN        NaN              NaN         NaN   \n",
      "1              0  ...        NaN        NaN              NaN         NaN   \n",
      "\n",
      "   setapneaippeephigh  setapnearr  setapneapeakflow  setapneainsptime  \\\n",
      "0                 NaN         NaN               NaN               NaN   \n",
      "1                 NaN         NaN               NaN               NaN   \n",
      "\n",
      "   setapneaie  setapneafio2  \n",
      "0         NaN           NaN  \n",
      "1         NaN           NaN  \n",
      "\n",
      "[2 rows x 34 columns] \n",
      "\n",
      "  respiratory_charting: (176089, 7)\n",
      "   respchartid  patientunitstayid  respchartoffset  respchartentryoffset  \\\n",
      "0          107             184757             2922                  2922   \n",
      "1         1108             187150              408                   408   \n",
      "\n",
      "   respcharttypecat respchartvaluelabel respchartvalue  \n",
      "0  respFlowSettings              LPM O2              1  \n",
      "1  respFlowSettings                FiO2             80   \n",
      "\n",
      "  treatment: (38290, 5)\n",
      "   treatmentid  patientunitstayid  treatmentoffset  \\\n",
      "0      9579899             242895              838   \n",
      "1      8788989             242895              512   \n",
      "\n",
      "                                     treatmentstring  activeupondischarge  \n",
      "0  cardiovascular|arrhythmias|anticoagulant admin...                False  \n",
      "1  cardiovascular|consultations|Cardiology consul...                False   \n",
      "\n",
      "  vital_periodic: (1634960, 19)\n",
      "   vitalperiodicid  patientunitstayid  observationoffset  temperature  sao2  \\\n",
      "0         29524122             141765               1179          NaN   NaN   \n",
      "1         29557845             141765                189          NaN  97.0   \n",
      "\n",
      "   heartrate  respiration  cvp  etco2  systemicsystolic  systemicdiastolic  \\\n",
      "0       82.0          NaN  NaN    NaN               NaN                NaN   \n",
      "1       76.0         30.0  NaN    NaN               NaN                NaN   \n",
      "\n",
      "   systemicmean  pasystolic  padiastolic  pamean  st1  st2  st3  icp  \n",
      "0           NaN         NaN          NaN     NaN  NaN  NaN  NaN  NaN  \n",
      "1           NaN         NaN          NaN     NaN  NaN  NaN  NaN  NaN   \n",
      "\n",
      "  note: (24758, 8)\n",
      "    noteid  patientunitstayid  noteoffset  noteenteredoffset  \\\n",
      "0  3594780             157427           1                  8   \n",
      "1  3594785             157427           1                  8   \n",
      "\n",
      "                 notetype                                           notepath  \\\n",
      "0  Comprehensive Progress  notes/Progress Notes/Admission Page One/Skip S...   \n",
      "1  Comprehensive Progress  notes/Progress Notes/Assessment and Plan/View ...   \n",
      "\n",
      "                      notevalue                      notetext  \n",
      "0  Include Past Medical History  Include Past Medical History  \n",
      "1                   System View                    SystemView   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Verify Shape & Columns\n",
    "for name, df in data_dict.items():\n",
    "    print(f\"  {name}: {df.shape}\")\n",
    "    print(df.head(2), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f26543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hospitalid', 'numbedscategory', 'teachingstatus', 'region'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(hospital.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0a8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_dx_cols = [\"patientunitstayid\", \"admitdxpath\", \"admitdxname\", \"admitdxtext\"]\n",
    "admission_drug_cols = [\"patientunitstayid\",\"drugname\",\"drugdosage\",\"drugunit\",\"drugadmitfrequency\"]\n",
    "allergy_cols = [\"patientunitstayid\",\"drugname\",\"allergytype\",\"allergyname\"]\n",
    "apache_aps_var_cols = [\"patientunitstayid\",\"intubated\", \"vent\", \"dialysis\", \"meds\",\"urine\", \"wbc\", \"temperature\", \"respiratoryrate\", \"heartrate\", \"meanbp\",\"creatinine\", \"bun\", \"pao2\", \"pco2\"]\n",
    "apache_patient_result_cols = [\"patientunitstayid\",\"acutephysiologyscore\", \"apachescore\",\"predictedicumortality\",\"predictedhospitalmortality\"]\n",
    "apache_pred_var_cols = [\"patientunitstayid\",\"saps3day1\", \"saps3today\", \"saps3yesterday\",\"age\", \"gender\",\n",
    "\"pao2\", \"fio2\", \"creatinine\",\"day1verbal\", \"day1motor\", \"day1eyes\",\"day1pao2\", \"day1fio2\",\n",
    "\"aids\", \"hepaticfailure\", \"lymphoma\", \"metastaticcancer\",\n",
    "\"leukemia\", \"immunosuppression\", \"cirrhosis\", \"diabetes\",\"admitdiagnosis\", \"admitsource\"]\n",
    "care_plan_care_provider_cols = [\"patientunitstayid\",\"providertype\",\"specialty\",\"managingphysician\"]\n",
    "care_plan_general_cols = [\"patientunitstayid\",\"cplgroup\",\"cplitemvalue\",\"activeupondischarge\"]\n",
    "care_plan_goal_cols= [\"patientunitstayid\",\"cplgoalcategory\",\"cplgoalvalue\",\"cplgoalstatus\",\"activeupondischarge\"]\n",
    "care_plan_infectious_disease_cols= [\"patientunitstayid\",\"activeupondischarge\",\"infectdiseasesite\",\"infectdiseaseassessment\",\"responsetotherapy\",\"treatment\"]\n",
    "custom_lab_cols = [\"patientunitstayid\",\"labothername\",\"labotherresult\",\"labothervaluetext\"]\n",
    "diagnosis_cols = [\"patientunitstayid\",\"activeupondischarge\",\"diagnosisstring\",\"icd9code\",\"diagnosispriority\"]\n",
    "hospital_cols = ['hospitalid', 'numbedscategory', 'teachingstatus', 'region']\n",
    "infusion_drug_cols = [\"patientunitstayid\",\"infusionoffset\",\"drugname\",\"drugrate\"]\n",
    "intake_output_cols = [\"patientunitstayid\",\"intakeoutputoffset\",\"intaketotal\",\"outputtotal\",\"dialysistotal\",\"nettotal\"]\n",
    "lab_cols = [\"patientunitstayid\",\"labresultoffset\",\"labname\",\"labresult\",\"labresulttext\"]\n",
    "medication_cols = [\"patientunitstayid\",\"drugstartoffset\",\"drugstopoffset\",\"drugordercancelled\",\"drugname\",\"dosage\",\"routeadmin\",\"frequency\",\"prn\"]\n",
    "micro_lab_cols = [\"patientunitstayid\",\"culturetakenoffset\",\"culturesite\",\"organism\",\"antibiotic\",\"sensitivitylevel\"]\n",
    "nurse_assessment_cols = [\"patientunitstayid\",\"nurseassessoffset\",\"cellattributepath\",\"celllabel\",\"cellattribute\",\"cellattributevalue\"]\n",
    "nurse_care_cols = [\"patientunitstayid\",\"nursecareoffset\",\"celllabel\",\"cellattributepath\",\"cellattribute\",\"cellattributevalue\"]\n",
    "nurse_charting_cols = [\"patientunitstayid\",\"nursingchartoffset\",\"nursingchartcelltypecat\",\"nursingchartcelltypevallabel\",\"nursingchartvalue\"]\n",
    "past_history_cols = [\"patientunitstayid\",\"pasthistorynotetype\",\"pasthistorypath\",\"pasthistoryvalue\",\"pasthistoryvaluetext\"]\n",
    "patient_cols = [\"patientunitstayid\",\"patienthealthsystemstayid\",\"gender\",\"age\",\"apacheadmissiondx\",\"admissionheight\",\n",
    "\"admissionweight\",\"dischargeweight\",\"hospitaladmitoffset\",\"hospitaldischargeoffset\",\"hospitaladmitsource\",\n",
    "\"hospitaldischargelocation\",\"hospitaldischargestatus\",\"unittype\",\"unitstaytype\",\"unitdischargestatus\",\"uniquepid\"]\n",
    "physical_exam_cols = ['patientunitstayid','physicalexamoffset','physicalexampath','physicalexamvalue','physicalexamtext']\n",
    "respiratory_care_cols = ['patientunitstayid','respcarestatusoffset','airwaytype','airwaysize','airwayposition','cuffpressure',             \n",
    "'ventstartoffset','ventendoffset', 'priorventstartoffset','priorventendoffset','meanairwaypreslimit','cpaplimit',                \n",
    "'peeplimit', 'setapneafio2']\n",
    "respiratory_charting_cols = ['patientunitstayid','respchartoffset','respcharttypecat','respchartvaluelabel','respchartvalue']\n",
    "treatment_cols = ['patientunitstayid','treatmentoffset','treatmentstring','activeupondischarge']\n",
    "vital_periodic_cols = ['patientunitstayid','observationoffset','temperature','sao2','heartrate','respiration','systemicsystolic',\n",
    "'systemicdiastolic','systemicmean']\n",
    "note_cols = ['patientunitstayid','noteoffset','notetype','notetext']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f52142",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_dx = admission_dx[admission_dx_cols]\n",
    "admission_drug = admission_drug[admission_drug_cols]\n",
    "allergy = allergy[allergy_cols]\n",
    "apache_aps_var = apache_aps_var[apache_aps_var_cols]\n",
    "apache_patient_result = apache_patient_result[apache_patient_result_cols]\n",
    "apache_pred_var = apache_pred_var[apache_pred_var_cols]\n",
    "care_plan_care_provider = care_plan_care_provider[care_plan_care_provider_cols]\n",
    "care_plan_general = care_plan_general[care_plan_general_cols]\n",
    "care_plan_goal = care_plan_goal[care_plan_goal_cols]\n",
    "care_plan_infectious_disease = care_plan_infectious_disease[care_plan_infectious_disease_cols]\n",
    "custom_lab = custom_lab[custom_lab_cols]\n",
    "diagnosis = diagnosis[diagnosis_cols]\n",
    "hospital = hospital[hospital_cols]\n",
    "infusion_drug = infusion_drug[infusion_drug_cols]\n",
    "intake_output = intake_output[intake_output_cols]\n",
    "lab =  lab [lab_cols]\n",
    "medication = medication[medication_cols]\n",
    "micro_lab  = micro_lab[micro_lab_cols]\n",
    "nurse_assessment = nurse_assessment[nurse_assessment_cols]\n",
    "past_history = past_history [past_history_cols]\n",
    "patient = patient [patient_cols]\n",
    "physical_exam = physical_exam[physical_exam_cols]\n",
    "respiratory_care = respiratory_care[respiratory_care_cols]\n",
    "respiratory_charting = respiratory_charting [respiratory_charting_cols]\n",
    "treatment = treatment [treatment_cols]\n",
    "vital_periodic = vital_periodic[vital_periodic_cols]\n",
    "note = note[note_cols]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d4ca038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "admission_dx_summary =(admission_dx.groupby ('patientunitstayid').size().reset_index(name ='admission_dx_count'))\n",
    "admission_drug_summary =(admission_drug.groupby ('patientunitstayid').size().reset_index(name ='admission_drug_count'))\n",
    "allergy_summary = (allergy.groupby ('patientunitstayid').size().reset_index(name ='allergy_count'))\n",
    "apache_aps_var_summary = (apache_aps_var.groupby ('patientunitstayid').size().reset_index(name ='apache_aps_var'))\n",
    "apache_patient_result_summary = (apache_patient_result.groupby ('patientunitstayid').size().reset_index(name ='apache_patient_result_count'))\n",
    "apache_pred_var_summary = (apache_pred_var.groupby ('patientunitstayid').size().reset_index(name ='apache_pred_var'))\n",
    "care_plan_care_provider_summary = (care_plan_care_provider.groupby ('patientunitstayid').size().reset_index(name ='care_plan_care_provider_count'))\n",
    "care_plan_general_summary =( care_plan_general.groupby ('patientunitstayid').size().reset_index(name ='care_plan_general_count'))\n",
    "care_plan_goal_summary = (care_plan_goal.groupby ('patientunitstayid').size().reset_index(name ='care_plan_goal_count'))\n",
    "care_plan_infectious_disease_summary = (care_plan_infectious_disease.groupby ('patientunitstayid').size().reset_index(name ='care_plan_infectious_disease_count'))\n",
    "custom_lab_summary = (custom_lab.groupby('patientunitstayid').size().reset_index(name='custom_lab_count'))\n",
    "diagnosis_summary = (diagnosis.groupby ('patientunitstayid').size().reset_index(name ='diagnosis_count'))\n",
    "hospital_summary = (hospital.groupby ('hospitalid').size().reset_index(name ='hospital_count'))\n",
    "infusion_drug_summary =(infusion_drug.groupby ('patientunitstayid').size().reset_index(name ='infusion_drug_count'))\n",
    "intake_output_summary =(intake_output.groupby ('patientunitstayid').size().reset_index(name ='intake_output_count'))\n",
    "lab_summary = (lab.groupby ('patientunitstayid').size().reset_index(name ='lab_count'))\n",
    "medication_summary=(medication.groupby ('patientunitstayid').size().reset_index(name ='medication_count'))\n",
    "micro_lab_summary =(micro_lab.groupby ('patientunitstayid').size().reset_index(name ='micro_lab_count'))\n",
    "nurse_assessment_summary = (nurse_assessment.groupby ('patientunitstayid').size().reset_index(name ='nurse_assessment_count'))\n",
    "past_history_summary= (past_history.groupby ('patientunitstayid').size().reset_index(name ='past_history_count'))\n",
    "patient_summary = (patient.groupby ('patientunitstayid').size().reset_index(name ='patient_count'))\n",
    "physical_exam_summary =(physical_exam.groupby ('patientunitstayid').size().reset_index(name ='physical_exam_count'))\n",
    "respiratory_care_summary = (respiratory_care.groupby ('patientunitstayid').size().reset_index(name ='respiratory_care_count'))\n",
    "respiratory_charting_summary =(respiratory_charting.groupby ('patientunitstayid').size().reset_index(name ='respiratory_charting_count'))\n",
    "treatment_summary = (treatment.groupby ('patientunitstayid').size().reset_index(name ='treatment_count'))\n",
    "vital_periodic_summary = (vital_periodic.groupby ('patientunitstayid').size().reset_index(name ='vital_periodic_count'))\n",
    "notes_summary = (note.groupby ('patientunitstayid').size().reset_index(name ='notes_count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492bb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged = data_dict['patient'][['patientunitstayid']]\n",
    "\n",
    "\n",
    "merged = merged.merge(admission_dx_summary, on='patientunitstayid', how='left')\n",
    "merged = merged.merge(admission_drug_summary, on='patientunitstayid', how='left')\n",
    "merged = merged.merge(allergy_summary, on='patientunitstayid', how='left')\n",
    "merged = merged.merge(apache_aps_var_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(apache_patient_result_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(apache_pred_var_summary,on ='patientunitstayid',how='left')\n",
    "merged = merged.merge(care_plan_care_provider_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(care_plan_goal_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(care_plan_infectious_disease_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(custom_lab_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(diagnosis_summary,on='patientunitstayid',how='left')\n",
    "#merged = merged.merge(hospital_summary,on='hospitalid',how='left')\n",
    "merged = merged.merge(infusion_drug_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(intake_output_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(lab_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(medication_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(micro_lab_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(nurse_assessment_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(past_history_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(patient_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(physical_exam_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(respiratory_care_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(respiratory_charting_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(treatment_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(vital_periodic_summary,on='patientunitstayid',how='left')\n",
    "merged = merged.merge(notes_summary,on='patientunitstayid',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b8b4297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patientunitstayid  admission_dx_count  admission_drug_count  allergy_count  \\\n",
      "0             141764                 0.0                   0.0            0.0   \n",
      "1             141765                 3.0                   0.0            0.0   \n",
      "2             143870                 4.0                   0.0            0.0   \n",
      "3             144815                 3.0                   0.0            0.0   \n",
      "4             145427                 4.0                   0.0            0.0   \n",
      "\n",
      "   apache_aps_var  apache_patient_result_count  apache_pred_var  \\\n",
      "0             0.0                          0.0              0.0   \n",
      "1             1.0                          2.0              1.0   \n",
      "2             1.0                          2.0              1.0   \n",
      "3             1.0                          2.0              1.0   \n",
      "4             1.0                          2.0              1.0   \n",
      "\n",
      "   care_plan_care_provider_count  care_plan_goal_count  \\\n",
      "0                            0.0                   0.0   \n",
      "1                            1.0                   0.0   \n",
      "2                            1.0                   0.0   \n",
      "3                            1.0                   0.0   \n",
      "4                            3.0                   0.0   \n",
      "\n",
      "   care_plan_infectious_disease_count  ...  micro_lab_count  \\\n",
      "0                                 0.0  ...              0.0   \n",
      "1                                 0.0  ...              0.0   \n",
      "2                                 0.0  ...              0.0   \n",
      "3                                 0.0  ...              0.0   \n",
      "4                                 0.0  ...              0.0   \n",
      "\n",
      "   nurse_assessment_count  past_history_count  patient_count  \\\n",
      "0                     0.0                 0.0              1   \n",
      "1                     0.0                 1.0              1   \n",
      "2                     0.0                 1.0              1   \n",
      "3                     0.0                 1.0              1   \n",
      "4                     0.0                 1.0              1   \n",
      "\n",
      "   physical_exam_count  respiratory_care_count  respiratory_charting_count  \\\n",
      "0                  0.0                     0.0                         0.0   \n",
      "1                  6.0                     0.0                         0.0   \n",
      "2                 14.0                     0.0                        10.0   \n",
      "3                 30.0                     0.0                         0.0   \n",
      "4                 15.0                     0.0                         8.0   \n",
      "\n",
      "   treatment_count  vital_periodic_count  notes_count  \n",
      "0              0.0                  69.0          0.0  \n",
      "1              0.0                 449.0          2.0  \n",
      "2              0.0                 158.0          3.0  \n",
      "3              0.0                 220.0          2.0  \n",
      "4              0.0                 238.0          2.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "(2520, 26)\n"
     ]
    }
   ],
   "source": [
    "merged = merged.fillna(0)\n",
    "print(merged.head())\n",
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c2355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\n",
    "    'admission_dx_count', 'admission_drug_count', 'allergy_count',\n",
    "    'apache_aps_var', 'apache_patient_result_count', 'apache_pred_var',\n",
    "    'care_plan_care_provider_count', 'care_plan_goal_count',\n",
    "    'care_plan_infectious_disease_count', 'custom_lab_count',\n",
    "    'diagnosis_count', 'infusion_drug_count', 'intake_output_count',\n",
    "    'lab_count', 'medication_count', 'micro_lab_count',\n",
    "    'nurse_assessment_count', 'past_history_count', 'patient_count',\n",
    "    'physical_exam_count', 'respiratory_care_count',\n",
    "    'respiratory_charting_count', 'treatment_count',\n",
    "    'vital_periodic_count', 'notes_count'\n",
    "]:\n",
    "    merged[col] = merged[col].fillna(0)\n",
    "\n",
    "# Drop duplicates\n",
    "merged.drop_duplicates(subset=['patientunitstayid'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60e346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 26) Index(['patientunitstayid', 'admission_dx_count', 'admission_drug_count',\n",
      "       'allergy_count', 'apache_aps_var', 'apache_patient_result_count',\n",
      "       'apache_pred_var', 'care_plan_care_provider_count',\n",
      "       'care_plan_goal_count', 'care_plan_infectious_disease_count',\n",
      "       'custom_lab_count', 'diagnosis_count', 'infusion_drug_count',\n",
      "       'intake_output_count', 'lab_count', 'medication_count',\n",
      "       'micro_lab_count', 'nurse_assessment_count', 'past_history_count',\n",
      "       'patient_count', 'physical_exam_count', 'respiratory_care_count',\n",
      "       'respiratory_charting_count', 'treatment_count', 'vital_periodic_count',\n",
      "       'notes_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# If merged is already created in your notebook\n",
    "# Just keep it as is, don't reload from CSV\n",
    "print(merged.shape, merged.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff30957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged dataframe once\n",
    "merged.to_csv(\"merged_patient_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99fda453",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"merged_patient_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd1e5a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noteid</th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>noteoffset</th>\n",
       "      <th>noteenteredoffset</th>\n",
       "      <th>notetype</th>\n",
       "      <th>notepath</th>\n",
       "      <th>notevalue</th>\n",
       "      <th>notetext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3594780</td>\n",
       "      <td>157427</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Comprehensive Progress</td>\n",
       "      <td>notes/Progress Notes/Admission Page One/Skip S...</td>\n",
       "      <td>Include Past Medical History</td>\n",
       "      <td>Include Past Medical History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3594785</td>\n",
       "      <td>157427</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Comprehensive Progress</td>\n",
       "      <td>notes/Progress Notes/Assessment and Plan/View ...</td>\n",
       "      <td>System View</td>\n",
       "      <td>SystemView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3594786</td>\n",
       "      <td>157427</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Comprehensive Progress</td>\n",
       "      <td>notes/Progress Notes/Assessment and Plan/Inclu...</td>\n",
       "      <td>Include Rx</td>\n",
       "      <td>Include Rx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3594787</td>\n",
       "      <td>157427</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Comprehensive Progress</td>\n",
       "      <td>notes/Shared/View and Save/Save Options/Print/...</td>\n",
       "      <td>Copies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3595514</td>\n",
       "      <td>238463</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>Comprehensive Progress</td>\n",
       "      <td>notes/Progress Notes/Assessment and Plan/View ...</td>\n",
       "      <td>System View</td>\n",
       "      <td>SystemView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24753</th>\n",
       "      <td>92018040</td>\n",
       "      <td>3329305</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>Admission</td>\n",
       "      <td>notes/Progress Notes/Assessment and Plan/View ...</td>\n",
       "      <td>System View</td>\n",
       "      <td>SystemView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24754</th>\n",
       "      <td>92018041</td>\n",
       "      <td>3329305</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>Admission</td>\n",
       "      <td>notes/Progress Notes/Assessment and Plan/Inclu...</td>\n",
       "      <td>Include Rx</td>\n",
       "      <td>Include Rx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24755</th>\n",
       "      <td>92018042</td>\n",
       "      <td>3329305</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>Admission</td>\n",
       "      <td>notes/Shared/View and Save/Save Options/Print/...</td>\n",
       "      <td>Copies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24756</th>\n",
       "      <td>92021621</td>\n",
       "      <td>3335354</td>\n",
       "      <td>460</td>\n",
       "      <td>461</td>\n",
       "      <td>Brief Progress</td>\n",
       "      <td>notes/Progress Notes/Interventions/Intermediat...</td>\n",
       "      <td>Medication change / dose adjustment</td>\n",
       "      <td>Medication change / dose adjustment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24757</th>\n",
       "      <td>92021622</td>\n",
       "      <td>3335354</td>\n",
       "      <td>460</td>\n",
       "      <td>461</td>\n",
       "      <td>Brief Progress</td>\n",
       "      <td>notes/Shared/View and Save/Save Options/Print/...</td>\n",
       "      <td>Copies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24758 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         noteid  patientunitstayid  noteoffset  noteenteredoffset  \\\n",
       "0       3594780             157427           1                  8   \n",
       "1       3594785             157427           1                  8   \n",
       "2       3594786             157427           1                  8   \n",
       "3       3594787             157427           1                  8   \n",
       "4       3595514             238463          19                 22   \n",
       "...         ...                ...         ...                ...   \n",
       "24753  92018040            3329305          19                 28   \n",
       "24754  92018041            3329305          19                 28   \n",
       "24755  92018042            3329305          19                 28   \n",
       "24756  92021621            3335354         460                461   \n",
       "24757  92021622            3335354         460                461   \n",
       "\n",
       "                     notetype  \\\n",
       "0      Comprehensive Progress   \n",
       "1      Comprehensive Progress   \n",
       "2      Comprehensive Progress   \n",
       "3      Comprehensive Progress   \n",
       "4      Comprehensive Progress   \n",
       "...                       ...   \n",
       "24753               Admission   \n",
       "24754               Admission   \n",
       "24755               Admission   \n",
       "24756          Brief Progress   \n",
       "24757          Brief Progress   \n",
       "\n",
       "                                                notepath  \\\n",
       "0      notes/Progress Notes/Admission Page One/Skip S...   \n",
       "1      notes/Progress Notes/Assessment and Plan/View ...   \n",
       "2      notes/Progress Notes/Assessment and Plan/Inclu...   \n",
       "3      notes/Shared/View and Save/Save Options/Print/...   \n",
       "4      notes/Progress Notes/Assessment and Plan/View ...   \n",
       "...                                                  ...   \n",
       "24753  notes/Progress Notes/Assessment and Plan/View ...   \n",
       "24754  notes/Progress Notes/Assessment and Plan/Inclu...   \n",
       "24755  notes/Shared/View and Save/Save Options/Print/...   \n",
       "24756  notes/Progress Notes/Interventions/Intermediat...   \n",
       "24757  notes/Shared/View and Save/Save Options/Print/...   \n",
       "\n",
       "                                 notevalue  \\\n",
       "0             Include Past Medical History   \n",
       "1                              System View   \n",
       "2                               Include Rx   \n",
       "3                                   Copies   \n",
       "4                              System View   \n",
       "...                                    ...   \n",
       "24753                          System View   \n",
       "24754                           Include Rx   \n",
       "24755                               Copies   \n",
       "24756  Medication change / dose adjustment   \n",
       "24757                               Copies   \n",
       "\n",
       "                                  notetext  \n",
       "0             Include Past Medical History  \n",
       "1                               SystemView  \n",
       "2                               Include Rx  \n",
       "3                                        1  \n",
       "4                               SystemView  \n",
       "...                                    ...  \n",
       "24753                           SystemView  \n",
       "24754                           Include Rx  \n",
       "24755                                    1  \n",
       "24756  Medication change / dose adjustment  \n",
       "24757                                    1  \n",
       "\n",
       "[24758 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = nlp_data['note.csv.gz']\n",
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9df35d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>notetext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141765</td>\n",
       "      <td>Problem View 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143870</td>\n",
       "      <td>Yes SystemView 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144815</td>\n",
       "      <td>SystemView 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145427</td>\n",
       "      <td>SystemView 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147307</td>\n",
       "      <td>Yes general SystemView 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>3351763</td>\n",
       "      <td>Pain - evaluation and management 1 Routine mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>3352230</td>\n",
       "      <td>1 Yes SystemView Unknown No DailyProgress 1 Ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>3352231</td>\n",
       "      <td>Include Allergies and Pre-Admission Meds Medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>3352333</td>\n",
       "      <td>1 Hypoxemia - evaluation and management 1 Rout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>3353113</td>\n",
       "      <td>SystemView 1 SystemView 1 Include Allergies an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2257 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patientunitstayid                                           notetext\n",
       "0                141765                                     Problem View 1\n",
       "1                143870                                   Yes SystemView 1\n",
       "2                144815                                       SystemView 1\n",
       "3                145427                                       SystemView 1\n",
       "4                147307                           Yes general SystemView 1\n",
       "...                 ...                                                ...\n",
       "2252            3351763  Pain - evaluation and management 1 Routine mod...\n",
       "2253            3352230  1 Yes SystemView Unknown No DailyProgress 1 Ye...\n",
       "2254            3352231  Include Allergies and Pre-Admission Meds Medic...\n",
       "2255            3352333  1 Hypoxemia - evaluation and management 1 Rout...\n",
       "2256            3353113  SystemView 1 SystemView 1 Include Allergies an...\n",
       "\n",
       "[2257 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaN with empty string\n",
    "notes['notetext'] = notes['notetext'].fillna('')\n",
    "\n",
    "# Now group by patient and concatenate\n",
    "patient_notes = notes.groupby('patientunitstayid')['notetext'] \\\n",
    "                     .apply(lambda x: ' '.join(x)) \\\n",
    "                     .reset_index()\n",
    "patient_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "963da65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>admission_dx_count</th>\n",
       "      <th>admission_drug_count</th>\n",
       "      <th>allergy_count</th>\n",
       "      <th>apache_aps_var</th>\n",
       "      <th>apache_patient_result_count</th>\n",
       "      <th>apache_pred_var</th>\n",
       "      <th>care_plan_care_provider_count</th>\n",
       "      <th>care_plan_goal_count</th>\n",
       "      <th>care_plan_infectious_disease_count</th>\n",
       "      <th>...</th>\n",
       "      <th>nurse_assessment_count</th>\n",
       "      <th>past_history_count</th>\n",
       "      <th>patient_count</th>\n",
       "      <th>physical_exam_count</th>\n",
       "      <th>respiratory_care_count</th>\n",
       "      <th>respiratory_charting_count</th>\n",
       "      <th>treatment_count</th>\n",
       "      <th>vital_periodic_count</th>\n",
       "      <th>notes_count</th>\n",
       "      <th>notetext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141765</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Problem View 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes SystemView 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144815</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SystemView 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145427</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SystemView 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientunitstayid  admission_dx_count  admission_drug_count  allergy_count  \\\n",
       "0             141764                 0.0                   0.0            0.0   \n",
       "1             141765                 3.0                   0.0            0.0   \n",
       "2             143870                 4.0                   0.0            0.0   \n",
       "3             144815                 3.0                   0.0            0.0   \n",
       "4             145427                 4.0                   0.0            0.0   \n",
       "\n",
       "   apache_aps_var  apache_patient_result_count  apache_pred_var  \\\n",
       "0             0.0                          0.0              0.0   \n",
       "1             1.0                          2.0              1.0   \n",
       "2             1.0                          2.0              1.0   \n",
       "3             1.0                          2.0              1.0   \n",
       "4             1.0                          2.0              1.0   \n",
       "\n",
       "   care_plan_care_provider_count  care_plan_goal_count  \\\n",
       "0                            0.0                   0.0   \n",
       "1                            1.0                   0.0   \n",
       "2                            1.0                   0.0   \n",
       "3                            1.0                   0.0   \n",
       "4                            3.0                   0.0   \n",
       "\n",
       "   care_plan_infectious_disease_count  ...  nurse_assessment_count  \\\n",
       "0                                 0.0  ...                     0.0   \n",
       "1                                 0.0  ...                     0.0   \n",
       "2                                 0.0  ...                     0.0   \n",
       "3                                 0.0  ...                     0.0   \n",
       "4                                 0.0  ...                     0.0   \n",
       "\n",
       "   past_history_count  patient_count  physical_exam_count  \\\n",
       "0                 0.0              1                  0.0   \n",
       "1                 1.0              1                  6.0   \n",
       "2                 1.0              1                 14.0   \n",
       "3                 1.0              1                 30.0   \n",
       "4                 1.0              1                 15.0   \n",
       "\n",
       "   respiratory_care_count  respiratory_charting_count  treatment_count  \\\n",
       "0                     0.0                         0.0              0.0   \n",
       "1                     0.0                         0.0              0.0   \n",
       "2                     0.0                        10.0              0.0   \n",
       "3                     0.0                         0.0              0.0   \n",
       "4                     0.0                         8.0              0.0   \n",
       "\n",
       "   vital_periodic_count  notes_count          notetext  \n",
       "0                  69.0          0.0               NaN  \n",
       "1                 449.0          2.0    Problem View 1  \n",
       "2                 158.0          3.0  Yes SystemView 1  \n",
       "3                 220.0          2.0      SystemView 1  \n",
       "4                 238.0          2.0      SystemView 1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge on patientunitstayid\n",
    "chatbot_data = merged.merge(patient_notes, on='patientunitstayid', how='left')\n",
    "\n",
    "# Check the result\n",
    "print(chatbot_data.shape)\n",
    "chatbot_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68f76706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of common symptoms and severity levels:\n",
    "triage_dict = {\n",
    "    \"fever\": {\"mild\": \"monitor at home\", \"moderate\": \"consult doctor\", \"high\": \"emergency\"},\n",
    "    \"cough\": {\"mild\": \"home care\", \"persistent\": \"see physician\"},\n",
    "    \"chest pain\": {\"any\": \"emergency\"}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7986940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When the patient enters a symptom, the bot can suggest next steps:\n",
    "def triage_bot(symptom, severity=\"any\"):\n",
    "    symptom = symptom.lower()\n",
    "    if symptom in triage_dict:\n",
    "        advice = triage_dict[symptom].get(severity, \"consult doctor for proper advice\")\n",
    "        return f\"Symptom: {symptom.title()} | Advice: {advice}\"\n",
    "    else:\n",
    "        return \"Symptom not recognized. Please enter another symptom.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34bfc2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Symptom: Fever | Advice: consult doctor'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to use it \n",
    "triage_bot(\"fever\", \"moderate\")\n",
    "# Output: \"Symptom: Fever | Advice: consult doctor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bd9e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appointment Scheduling\n",
    "# Simulate available slots:\n",
    "\n",
    "appointments = {\n",
    "    \"Dr. Smith\": [\"2025-09-12 10:00\", \"2025-09-12 14:00\"],\n",
    "    \"Dr. Lee\": [\"2025-09-13 09:00\", \"2025-09-13 15:00\"]\n",
    "}\n",
    "\n",
    "def book_appointment(doctor, slot):\n",
    "    if doctor in appointments and slot in appointments[doctor]:\n",
    "        appointments[doctor].remove(slot)\n",
    "        return f\"Appointment booked with {doctor} at {slot}\"\n",
    "    else:\n",
    "        return \"Selected slot not available. Please choose another.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae08ba3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Appointment booked with Dr. Smith at 2025-09-12 10:00'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_appointment(\"Dr. Smith\", \"2025-09-12 10:00\")\n",
    "# Output: \"Appointment booked with Dr. Smith at 2025-09-12 10:00\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80f104b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAQ'S\n",
    "\n",
    "faq_dict = {\n",
    "    \"visiting hours\": \"Visiting hours are 9 AM to 6 PM daily.\",\n",
    "    \"payment methods\": \"We accept cash, card, and online payments.\",\n",
    "    \"emergency contact\": \"Call 911 for emergencies or hospital reception for urgent queries.\"\n",
    "}\n",
    "\n",
    "def answer_faq(question):\n",
    "    question = question.lower()\n",
    "    for key in faq_dict:\n",
    "        if key in question:\n",
    "            return faq_dict[key]\n",
    "    return \"Sorry, I don’t have an answer for that. Please contact the hospital.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "723a8d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visiting hours are 9 AM to 6 PM daily.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_faq(\"What are visiting hours?\")\n",
    "# Output: \"Visiting hours are 9 AM to 6 PM daily.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c1ecd",
   "metadata": {},
   "source": [
    "ChatGPT said:\n",
    "\n",
    "Healthcare Chatbot – Brief Summary\n",
    "\n",
    "Goal:\n",
    "Develop a chatbot for patient triage, appointment booking, note retrieval, and FAQs.\n",
    "\n",
    "Features:\n",
    "\n",
    "Patient Summary: Shows counts of labs, meds, notes, and assessments.\n",
    "\n",
    "Notes Retrieval: Searches and summarizes clinical notes.\n",
    "\n",
    "Symptom Triage: Offers guidance based on severity.\n",
    "\n",
    "Appointment Scheduling: Books available doctor slots.\n",
    "\n",
    "FAQs: Answers common hospital questions.\n",
    "\n",
    "Data:\n",
    "Uses PhysioNet datasets (patient, lab, medication, note, etc.).\n",
    "\n",
    "Outcome:\n",
    "A working chatbot for triage, scheduling, summaries, and FAQs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e051064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcefb9ec",
   "metadata": {},
   "source": [
    "CHATBOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdbfa15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c86bc69fa94632a0b96a1b49173d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a53cd66ba04300919fe86c0da100b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c609fa90ac3e47cfaee6a92f9c12759c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab71ecc371ba41048015f0481fd7c59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad4e80d1dec426387aec6abe14878d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/351M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a6224cd56746dabc87de41c840e994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'exit' to end the chat.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Yes, that's why I'm looking for a new dentist.\n",
      "Chatbot: I've been looking for an appointment for a month now.\n",
      "Chatbot: It's a Dio!\n",
      "Chatbot: I live in the states. I'm not sure what it is.\n",
      "Chatbot: I'm not a native speaker, I'm a native English speaker, and I'm just trying to find a time to visit the US.\n",
      "Chatbot: What is a visiting time?\n",
      "Chatbot: Please provide a valid patient ID.\n",
      "Chatbot: ” “ “... ” ”\n",
      "Chatbot: . “\n",
      "Chatbot: .\n",
      "Chatbot: so?\n",
      "Chatbot: what medication\n",
      "Chatbot: wrong “ is that\n",
      "Chatbot: ... “ you “ are you\n",
      "Chatbot: about:\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load model\n",
    "model_name = \"microsoft/DialoGPT-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Example hospital dataset (replace with your merged dataframe)\n",
    "import pandas as pd\n",
    "data = {\n",
    "    \"patientunitstayid\": [141764, 157427],\n",
    "    \"lab_count\": [0, 60],\n",
    "    \"medications\": [5, 22]\n",
    "}\n",
    "merged = pd.DataFrame(data)\n",
    "\n",
    "# Function to check dataset queries\n",
    "def check_patient_query(user_input):\n",
    "    if \"patient\" in user_input.lower():\n",
    "        try:\n",
    "            pid = int(user_input.split()[-1])  # last word as patient ID\n",
    "            row = merged[merged['patientunitstayid'] == pid]\n",
    "            if not row.empty:\n",
    "                return (f\"Patient {pid} summary:\\n\"\n",
    "                        f\"- Number of lab tests: {row.iloc[0]['lab_count']}\\n\"\n",
    "                        f\"- Medications administered: {row.iloc[0]['medications']}\")\n",
    "            else:\n",
    "                return f\"No data found for Patient {pid}.\"\n",
    "        except:\n",
    "            return \"Please provide a valid patient ID.\"\n",
    "    return None\n",
    "\n",
    "# Chatbot loop\n",
    "print(\"Chatbot is ready! Type 'exit' to end the chat.\\n\")\n",
    "chat_history_ids = None\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # 🔹 First check dataset queries\n",
    "    custom_response = check_patient_query(user_input)\n",
    "    if custom_response:\n",
    "        print(f\"Chatbot: {custom_response}\")\n",
    "        continue\n",
    "\n",
    "    # 🔹 Else use DialoGPT for open-ended chat\n",
    "    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if chat_history_ids is not None else new_user_input_ids\n",
    "\n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        max_length=1000,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        do_sample=True,\n",
    "        top_k=100,\n",
    "        top_p=0.7,\n",
    "        temperature=0.8\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    print(f\"Chatbot: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb86a26",
   "metadata": {},
   "source": [
    "RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3591b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.56.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Downloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-5.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25c469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf42e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\programdata\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (3.11.3)\n",
      "Collecting keras-core\n",
      "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.56.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (0.17.0)\n",
      "Collecting dm-tree (from keras-core)\n",
      "  Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dm-tree->keras-core) (25.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
      "   ---------------------------------------- 0.0/950.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/950.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/950.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/950.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/950.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/950.8 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 786.4/950.8 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 950.8/950.8 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Installing collected packages: dm-tree, keras-core\n",
      "Successfully installed dm-tree-0.1.9 keras-core-0.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers tensorflow keras keras-core\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8689cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.11.3\n",
      "Uninstalling keras-3.11.3:\n",
      "  Successfully uninstalled keras-3.11.3\n",
      "Found existing installation: keras-core 0.1.7\n",
      "Uninstalling keras-core-0.1.7:\n",
      "  Successfully uninstalled keras-core-0.1.7\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Collecting keras>=3.10.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.7 MB/s eta 0:00:00\n",
      "Using cached keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: keras, tf-keras\n",
      "Successfully installed keras-3.11.3 tf-keras-2.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y keras keras-core\n",
    "!pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47ac1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2878f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa6339be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp312-cp312-win_amd64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.12.0-cp312-cp312-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.2 MB 1.0 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.8/18.2 MB 1.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.8/18.2 MB 1.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.8/18.2 MB 1.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.8/18.2 MB 1.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.8/18.2 MB 1.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.8/18.2 MB 1.2 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 1.0/18.2 MB 493.4 kB/s eta 0:00:35\n",
      "   -- ------------------------------------- 1.0/18.2 MB 493.4 kB/s eta 0:00:35\n",
      "   -- ------------------------------------- 1.3/18.2 MB 508.5 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 1.6/18.2 MB 566.9 kB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 1.8/18.2 MB 621.4 kB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 2.1/18.2 MB 667.3 kB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 2.4/18.2 MB 699.0 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 2.6/18.2 MB 725.9 kB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 2.6/18.2 MB 725.9 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 2.9/18.2 MB 745.8 kB/s eta 0:00:21\n",
      "   ------ --------------------------------- 3.1/18.2 MB 769.0 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 3.4/18.2 MB 786.4 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 3.7/18.2 MB 807.7 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 3.9/18.2 MB 827.1 kB/s eta 0:00:18\n",
      "   --------- ------------------------------ 4.2/18.2 MB 833.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 4.5/18.2 MB 863.2 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 5.0/18.2 MB 923.6 kB/s eta 0:00:15\n",
      "   ------------ --------------------------- 5.5/18.2 MB 978.3 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 5.8/18.2 MB 992.4 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 6.0/18.2 MB 1.0 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 6.3/18.2 MB 1.0 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 6.8/18.2 MB 1.1 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 7.1/18.2 MB 1.1 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 7.6/18.2 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 7.9/18.2 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 8.1/18.2 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 8.7/18.2 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 9.2/18.2 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 9.4/18.2 MB 1.2 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 9.7/18.2 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 10.2/18.2 MB 1.2 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 10.5/18.2 MB 1.2 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 10.7/18.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 11.0/18.2 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 11.5/18.2 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 11.8/18.2 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 12.1/18.2 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 12.6/18.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 13.1/18.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 13.4/18.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 13.9/18.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 14.2/18.2 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 14.7/18.2 MB 1.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 14.9/18.2 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 15.5/18.2 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 15.7/18.2 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 16.0/18.2 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 16.5/18.2 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 16.8/18.2 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.3/18.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/18.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.1/18.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n",
      "FAISS version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install\n",
    "!pip install faiss-cpu\n",
    "\n",
    "# Step 2: Restart the runtime/kernel (do this manually)\n",
    "\n",
    "# Step 3: Import and test\n",
    "import faiss\n",
    "print(\"FAISS version:\", faiss.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "142d268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import time, json, os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Example: load FAQ CSV or text files into `docs` list of dicts\n",
    "# docs = [{\"source_id\": \"faq_01\", \"title\":\"visiting hours\", \"text\":\"Visiting hours are 9 AM to 6 PM daily.\"}, ...]\n",
    "# For your notes: create docs from patient notes but avoid PII in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5085d8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def chunk_text(text, chunk_size=400, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        chunk = \" \".join(words[i:i+chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        i += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# Example create corpus from one dataframe column\n",
    "docs = []\n",
    "# Suppose faq_df with columns ['id','question','answer']\n",
    "# for idx,row in faq_df.iterrows():\n",
    "#     docs.append({\"source_id\": f\"faq_{row['id']}\", \"title\": row['question'], \"text\": row['answer']})\n",
    "\n",
    "# For demonstration, small corpus:\n",
    "docs = [\n",
    "    {\"source_id\":\"faq_1\",\"title\":\"visiting hours\",\"text\":\"Visiting hours are 9 AM to 6 PM daily.\"},\n",
    "    {\"source_id\":\"guideline_1\",\"title\":\"chest_pain\",\"text\":\"Chest pain requires immediate ER evaluation if severe or associated with breathlessness.\"}\n",
    "]\n",
    "\n",
    "# Expand docs into chunks list\n",
    "chunks = []\n",
    "for d in docs:\n",
    "    for c in chunk_text(d['text'], chunk_size=100, overlap=20):\n",
    "        chunks.append({\"source_id\": d['source_id'], \"title\": d['title'], \"text\": c})\n",
    "print(f\"Total chunks: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b5bba",
   "metadata": {},
   "source": [
    "Compute embeddings (use clinical sentence-transformer if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0458d2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d801d56f22d7436fb89a6a06ea2dc4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0b004eef704e0ba857e09ade82dc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33319a5fa1146668e4aa2b99d4666e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d30dab4d47483fad80e65aa73f4945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b47145b044bc2bc927a43dfecf8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868ad7f46e8a4a1aa217f6b28631ec9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ae7a66c6504b7b8637e4b543d9bc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55032b891d484bb7a7193773296f193b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d6dc0038944e48a5b8e28fb1dce717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246aa4f627c1462e8f2a3dd008e2cd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f233117de74243bb78c6972cecdbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017fd8a252604f5e90bc2dac75ac167f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose a model; there are clinical SBERT models (if you have them). Example:\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # swap for clinical variant if available\n",
    "\n",
    "texts = [c['text'] for c in chunks]\n",
    "embs = embed_model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7c67e",
   "metadata": {},
   "source": [
    "Build FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c4ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = embs.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embs)  # add vectors\n",
    "# keep metadata mapping\n",
    "metadata = chunks  # same order as embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8bfcc7",
   "metadata": {},
   "source": [
    "Load generator (Hugging Face model or use pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8212d4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb9ffe62f6541bfaa337242e814be05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5c509d491c415bb2033e765995a358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac120f55b1f488cb5d6ff96fb928a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37673aef2060415faa46917399e30408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cfa26f02074c8ebde26e5fbe0aca82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055ef177b7544b699e349db65b5308b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38a4ab149214fe2b550020712b0e87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Light-weight: use a HF causal model (change to a chat model if you have one)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # replace with a stronger HF chat model (requires proper tokenizer)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")  # example only - use larger model for real use\n",
    "\n",
    "gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af1241",
   "metadata": {},
   "source": [
    "RAG query function (retrieve + generate with citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5dc0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, k=3):\n",
    "    q_emb = embed_model.encode([query], convert_to_numpy=True)\n",
    "    D, I = index.search(q_emb, k)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        results.append(metadata[idx])\n",
    "    return results\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a helpful and conservative medical assistant. Use ONLY the provided sources to answer. \n",
    "Cite each sentence with the source id in square brackets like [faq_1]. \n",
    "If the answer is not found in the sources, say: \"I don't have authoritative info to answer that.\" \n",
    "\n",
    "Sources:\n",
    "{sources}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "def rag_answer(question, k=3):\n",
    "    start = time.time()\n",
    "    retrieved = retrieve(question, k=k)\n",
    "    # build sources block\n",
    "    sources_block = \"\\n\".join([f\"[{r['source_id']}] {r['title']}: {r['text']}\" for r in retrieved])\n",
    "    prompt = PROMPT_TEMPLATE.format(sources=sources_block, question=question)\n",
    "    # generation (short max length)\n",
    "    out = gen(prompt, max_length=256, do_sample=False)[0]['generated_text']\n",
    "    latency = time.time() - start\n",
    "    # Optionally extract the answer portion after \"Answer:\" label\n",
    "    if \"Answer:\" in out:\n",
    "        answer = out.split(\"Answer:\")[-1].strip()\n",
    "    else:\n",
    "        answer = out\n",
    "    return answer, retrieved, latency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780d52b6",
   "metadata": {},
   "source": [
    "Logging + human evaluation UI (Gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43f48043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\asus\\AppData\\Local\\Temp\\pip-uninstall-daguub5y'."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading gradio-5.45.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading Brotli-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.13.0 (from gradio)\n",
      "  Downloading gradio_client-1.13.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (0.34.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.13.0-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.17.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio) (4.14.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from gradio-client==1.13.0->gradio) (2024.6.1)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.13.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.47.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading gradio-5.45.0-py3-none-any.whl (60.4 MB)\n",
      "   ---------------------------------------- 0.0/60.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/60.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/60.4 MB 2.6 MB/s eta 0:00:24\n",
      "    --------------------------------------- 1.3/60.4 MB 2.6 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 1.6/60.4 MB 2.2 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 2.1/60.4 MB 2.3 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 2.6/60.4 MB 2.4 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 3.1/60.4 MB 2.4 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 3.9/60.4 MB 2.5 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 4.5/60.4 MB 2.5 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 5.0/60.4 MB 2.5 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 5.5/60.4 MB 2.6 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 6.0/60.4 MB 2.6 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 6.8/60.4 MB 2.6 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 7.3/60.4 MB 2.6 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 8.1/60.4 MB 2.7 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 8.4/60.4 MB 2.7 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 8.9/60.4 MB 2.6 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 9.4/60.4 MB 2.6 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 9.7/60.4 MB 2.6 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 10.2/60.4 MB 2.6 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 10.5/60.4 MB 2.5 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 11.0/60.4 MB 2.5 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 11.5/60.4 MB 2.5 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 12.1/60.4 MB 2.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 12.6/60.4 MB 2.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 13.1/60.4 MB 2.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 13.6/60.4 MB 2.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 14.2/60.4 MB 2.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 14.7/60.4 MB 2.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 14.9/60.4 MB 2.5 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 15.5/60.4 MB 2.5 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 16.0/60.4 MB 2.5 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 16.5/60.4 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 17.0/60.4 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 17.6/60.4 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 18.1/60.4 MB 2.5 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 18.6/60.4 MB 2.5 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 19.1/60.4 MB 2.5 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 19.4/60.4 MB 2.5 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 19.9/60.4 MB 2.5 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 20.4/60.4 MB 2.5 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 21.0/60.4 MB 2.5 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 21.5/60.4 MB 2.4 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 21.8/60.4 MB 2.4 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 22.0/60.4 MB 2.4 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 22.5/60.4 MB 2.4 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 23.1/60.4 MB 2.4 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 23.3/60.4 MB 2.4 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 23.6/60.4 MB 2.4 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 23.9/60.4 MB 2.4 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 24.4/60.4 MB 2.3 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 24.6/60.4 MB 2.3 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 25.2/60.4 MB 2.3 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 25.7/60.4 MB 2.3 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 26.0/60.4 MB 2.3 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 26.5/60.4 MB 2.3 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 26.7/60.4 MB 2.3 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 27.3/60.4 MB 2.3 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 27.8/60.4 MB 2.3 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 28.3/60.4 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 28.8/60.4 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 29.1/60.4 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 29.6/60.4 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 29.9/60.4 MB 2.3 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 30.4/60.4 MB 2.3 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 30.9/60.4 MB 2.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 31.5/60.4 MB 2.3 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 32.0/60.4 MB 2.3 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 32.2/60.4 MB 2.3 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 32.8/60.4 MB 2.3 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 33.3/60.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 33.8/60.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 34.3/60.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 34.6/60.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 35.1/60.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 35.7/60.4 MB 2.3 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 36.2/60.4 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 36.7/60.4 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 37.0/60.4 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 37.5/60.4 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 37.7/60.4 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 38.3/60.4 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 38.5/60.4 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 39.1/60.4 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 39.3/60.4 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 39.8/60.4 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 40.1/60.4 MB 2.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 40.6/60.4 MB 2.2 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 41.2/60.4 MB 2.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 41.4/60.4 MB 2.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 41.9/60.4 MB 2.3 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 42.5/60.4 MB 2.3 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 43.0/60.4 MB 2.3 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 43.3/60.4 MB 2.2 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 43.8/60.4 MB 2.2 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 44.3/60.4 MB 2.2 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 44.6/60.4 MB 2.2 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 45.1/60.4 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 45.6/60.4 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 46.1/60.4 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 46.7/60.4 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 46.9/60.4 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 47.4/60.4 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 47.7/60.4 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 48.2/60.4 MB 2.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 48.8/60.4 MB 2.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 49.3/60.4 MB 2.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 49.5/60.4 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 49.8/60.4 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 50.1/60.4 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 50.6/60.4 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 50.9/60.4 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 51.4/60.4 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 51.9/60.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 52.4/60.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 53.0/60.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 53.5/60.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 53.7/60.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 54.3/60.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 54.8/60.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 55.3/60.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 55.8/60.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 56.4/60.4 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 56.9/60.4 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 57.1/60.4 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 57.4/60.4 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 57.7/60.4 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 58.2/60.4 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 58.7/60.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  59.0/60.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  59.5/60.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  60.0/60.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  60.3/60.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 60.4/60.4 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.13.0-py3-none-any.whl (325 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading Brotli-1.1.0-cp312-cp312-win_amd64.whl (357 kB)\n",
      "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.13.0-py3-none-win_amd64.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.3 MB 1.5 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.0/13.3 MB 1.7 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.3/13.3 MB 1.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/13.3 MB 1.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.1/13.3 MB 1.8 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.6/13.3 MB 1.8 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.9/13.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.4/13.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.4/13.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.9/13.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 4.2/13.3 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 4.7/13.3 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 5.0/13.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 5.5/13.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 5.8/13.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 6.3/13.3 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.6/13.3 MB 1.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 7.1/13.3 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 7.3/13.3 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 7.9/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.1/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.4/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 8.9/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 9.4/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 9.7/13.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.2/13.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.5/13.3 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 11.0/13.3 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 11.3/13.3 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.8/13.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.1/13.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.6/13.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.47.3-py3-none-any.whl (72 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading typer-0.17.4-py3-none-any.whl (46 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Installing collected packages: pydub, brotli, websockets, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, uvicorn, starlette, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: brotli\n",
      "    Found existing installation: Brotli 1.0.9\n",
      "    Uninstalling Brotli-1.0.9:\n",
      "      Successfully uninstalled Brotli-1.0.9\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.9.0\n",
      "    Uninstalling typer-0.9.0:\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "Successfully installed aiofiles-24.1.0 brotli-1.1.0 fastapi-0.116.1 ffmpy-0.6.1 gradio-5.45.0 gradio-client-1.13.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.13.0 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.47.3 tomlkit-0.13.3 typer-0.17.4 uvicorn-0.35.0 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1be9863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import csv, time\n",
    "\n",
    "EVAL_FILE = \"chatbot_eval.csv\"\n",
    "if not os.path.exists(EVAL_FILE):\n",
    "    pd.DataFrame(columns=[\"timestamp\",\"user_query\",\"bot_response\",\"sources\",\"latency\",\"relevance\",\"faithfulness\"]).to_csv(EVAL_FILE,index=False)\n",
    "\n",
    "def chat_and_log(user_query):\n",
    "    ans, retrieved, latency = rag_answer(user_query, k=3)\n",
    "    sources = \";\".join([r['source_id'] for r in retrieved])\n",
    "    # Return response + metadata; ratings will be provided by user in the UI\n",
    "    return ans, sources, round(latency,3)\n",
    "\n",
    "def save_ratings(user_query, bot_response, sources, latency, relevance, faithfulness):\n",
    "    row = {\n",
    "        \"timestamp\": time.time(),\n",
    "        \"user_query\": user_query,\n",
    "        \"bot_response\": bot_response,\n",
    "        \"sources\": sources,\n",
    "        \"latency\": latency,\n",
    "        \"relevance\": relevance,\n",
    "        \"faithfulness\": faithfulness\n",
    "    }\n",
    "    df = pd.read_csv(EVAL_FILE)\n",
    "    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "    df.to_csv(EVAL_FILE, index=False)\n",
    "    return \"Saved\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    inp = gr.Textbox(label=\"User question\")\n",
    "    out = gr.Textbox(label=\"Chatbot answer\", interactive=False)\n",
    "    src = gr.Textbox(label=\"Retrieved sources\", interactive=False)\n",
    "    lat = gr.Textbox(label=\"Latency (s)\", interactive=False)\n",
    "    btn = gr.Button(\"Ask\")\n",
    "    with gr.Row():\n",
    "        rel = gr.Slider(1,5,value=5,label=\"Relevance (1-5)\")\n",
    "        fai = gr.Slider(1,5,value=5,label=\"Faithfulness (1-5)\")\n",
    "    save_btn = gr.Button(\"Save rating\")\n",
    "    btn.click(fn=chat_and_log, inputs=inp, outputs=[out,src,lat])\n",
    "    save_btn.click(fn=save_ratings, inputs=[inp,out,src,lat,rel,fai], outputs=gr.Textbox())\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dafe1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9776707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\programdata\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (3.7.5)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlxtend\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
