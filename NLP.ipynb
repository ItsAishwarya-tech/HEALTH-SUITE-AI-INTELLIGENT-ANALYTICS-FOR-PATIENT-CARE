{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0064d24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded ML file: admissionDx.csv.gz | Shape: (7578, 6)\n",
      "✅ Loaded ML file: admissiondrug.csv.gz | Shape: (7417, 14)\n",
      "✅ Loaded ML file: allergy.csv.gz | Shape: (2475, 13)\n",
      "✅ Loaded ML file: apacheApsVar.csv.gz | Shape: (2205, 26)\n",
      "✅ Loaded ML file: apachePatientResult.csv.gz | Shape: (3676, 23)\n",
      "✅ Loaded ML file: apachePredVar.csv.gz | Shape: (2205, 51)\n",
      "✅ Loaded ML file: carePlanCareProvider.csv.gz | Shape: (5627, 8)\n",
      "✅ Loaded ML file: carePlanGeneral.csv.gz | Shape: (33148, 6)\n",
      "✅ Loaded ML file: carePlanGoal.csv.gz | Shape: (3633, 7)\n",
      "✅ Loaded ML file: carePlanInfectiousDisease.csv.gz | Shape: (112, 8)\n",
      "✅ Loaded ML file: customLab.csv.gz | Shape: (30, 7)\n",
      "✅ Loaded ML file: diagnosis.csv.gz | Shape: (24978, 7)\n",
      "✅ Loaded ML file: hospital.csv.gz | Shape: (186, 4)\n",
      "✅ Loaded ML file: infusiondrug.csv.gz | Shape: (38256, 9)\n",
      "✅ Loaded ML file: intakeOutput.csv.gz | Shape: (100466, 12)\n",
      "✅ Loaded ML file: lab.csv.gz | Shape: (434660, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_31244\\1253520010.py:32: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ml_data[file] = pd.read_csv(path, compression='gzip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded ML file: medication.csv.gz | Shape: (75604, 15)\n",
      "✅ Loaded ML file: microLab.csv.gz | Shape: (342, 7)\n",
      "✅ Loaded ML file: nurseAssessment.csv.gz | Shape: (91589, 8)\n",
      "✅ Loaded ML file: nurseCare.csv.gz | Shape: (42080, 8)\n",
      "✅ Loaded ML file: nurseCharting.csv.gz | Shape: (1477163, 8)\n",
      "✅ Loaded ML file: pastHistory.csv.gz | Shape: (12109, 8)\n",
      "✅ Loaded ML file: patient.csv.gz | Shape: (2520, 29)\n",
      "✅ Loaded ML file: physicalExam.csv.gz | Shape: (84058, 6)\n",
      "✅ Loaded ML file: respiratoryCare.csv.gz | Shape: (5436, 34)\n",
      "✅ Loaded ML file: respiratoryCharting.csv.gz | Shape: (176089, 7)\n",
      "✅ Loaded ML file: treatment.csv.gz | Shape: (38290, 5)\n",
      "✅ Loaded ML file: vitalPeriodic.csv.gz | Shape: (1634960, 19)\n",
      "✅ Loaded NLP file: note.csv.gz | Shape: (24758, 8)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Change this to your actual folder path\n",
    "data_folder = r\"C:\\Users\\asus\\Downloads\\health api\"\n",
    "\n",
    "# ML and NLP file lists\n",
    "ml_files = [\n",
    "    'admissionDx.csv.gz', 'admissiondrug.csv.gz', 'allergy.csv.gz', 'apacheApsVar.csv.gz',\n",
    "    'apachePatientResult.csv.gz', 'apachePredVar.csv.gz', 'carePlanCareProvider.csv.gz',\n",
    "    'carePlanGeneral.csv.gz', 'carePlanGoal.csv.gz',\n",
    "    'carePlanInfectiousDisease.csv.gz', 'customLab.csv.gz', 'diagnosis.csv.gz',\n",
    "    'hospital.csv.gz', 'infusiondrug.csv.gz', 'intakeOutput.csv.gz', 'lab.csv.gz',\n",
    "    'medication.csv.gz', 'microLab.csv.gz', 'nurseAssessment.csv.gz', 'nurseCare.csv.gz',\n",
    "    'nurseCharting.csv.gz', 'pastHistory.csv.gz', 'patient.csv.gz', 'physicalExam.csv.gz',\n",
    "    'respiratoryCare.csv.gz', 'respiratoryCharting.csv.gz', 'treatment.csv.gz',\n",
    "     'vitalPeriodic.csv.gz'\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "nlp_files = ['note.csv.gz']\n",
    "\n",
    "# Dictionaries to store data\n",
    "ml_data = {}\n",
    "nlp_data = {}\n",
    "\n",
    "# Load ML files\n",
    "for file in ml_files:\n",
    "    path = os.path.join(data_folder, file)\n",
    "    if os.path.exists(path):\n",
    "        ml_data[file] = pd.read_csv(path, compression='gzip')\n",
    "        print(f\"✅ Loaded ML file: {file} | Shape: {ml_data[file].shape}\")\n",
    "    else:\n",
    "        print(f\" Missing ML file: {file}\")\n",
    "        \n",
    "# Load NLP files\n",
    "for file in nlp_files:\n",
    "    path = os.path.join(data_folder, file)\n",
    "    if os.path.exists(path):\n",
    "        nlp_data[file] = pd.read_csv(path, compression='gzip')\n",
    "        print(f\"✅ Loaded NLP file: {file} | Shape: {nlp_data[file].shape}\")\n",
    "    else:\n",
    "        print(f\"❌ Missing NLP file: {file}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96491ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#patient = ml_data['patient.csv.gz']\n",
    "admission_dx = ml_data['admissionDx.csv.gz']\n",
    "#medication = ml_data['medication.csv.gz']\n",
    "lab = ml_data['lab.csv.gz']\n",
    "allergy = ml_data['allergy.csv.gz']\n",
    "clinical_notes = nlp_data['note.csv.gz']\n",
    "clinical_scores = ml_data['apacheApsVar.csv.gz']\n",
    "nurse_assessment = ml_data['nurseAssessment.csv.gz']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'admissionDx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(admissionDx\u001b[38;5;241m.\u001b[39mcsv\u001b[38;5;241m.\u001b[39mgz\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'admissionDx' is not defined"
     ]
    }
   ],
   "source": [
    "print(admissionDx.csv.gz.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b91f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "admission_dx_cols = ['patientunitstayid', 'admitdxtext']\n",
    "clinical_notes_cols = ['patientunitstayid', 'notetext', 'notevalue']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fa1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_dx = admission_dx[admission_dx_cols]\n",
    "clinical_notes = clinical_notes[clinical_notes_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b273ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_dx_summary = ( admission_dx .groupby('patientunitstayid') .size() .reset_index(name='admission_dx_count'))\n",
    "clinical_notes_summary = ( clinical_notes .groupby('patientunitstayid') .size() .reset_index(name='clinical_notes_count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6fc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = ml_data['patient.csv.gz'][['patientunitstayid']]\n",
    "merged = merged.merge(admission_dx_summary, on='patientunitstayid', how='left')\n",
    "merged = merged.merge(clinical_notes_summary, on='patientunitstayid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b80a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[['admission_dx_count', 'clinical_notes_count']] = (\n",
    "    merged[['admission_dx_count', 'clinical_notes_count']].fillna(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1ab65",
   "metadata": {},
   "source": [
    "DATA PRRPROCESSING \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d804c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patientunitstayid                                       cleaned_text\n",
      "0            2900423     cardiovascular medical records medical records\n",
      "1            2900423                 cardiovascular performed performed\n",
      "2            2900423  cardiovascular smoker duration unknown smoker ...\n",
      "3            2900423                           cardiovascular none none\n",
      "4            2900423      cardiovascular notsignificant not significant\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Merge admission dx and notes\n",
    "nlp_df = pd.merge(admission_dx, clinical_notes, on='patientunitstayid', how='outer')\n",
    "\n",
    "# Combine columns into a single text field\n",
    "nlp_df['combined_text'] = nlp_df[['admitdxtext', 'notetext', 'notevalue']].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()                          # lowercase\n",
    "    text = re.sub(r'\\d+', '', text)             # remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)         # remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    # remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "nlp_df['cleaned_text'] = nlp_df['combined_text'].apply(clean_text)\n",
    "\n",
    "print(nlp_df[['patientunitstayid', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c41c95",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (97732650.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install transformers\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#ready to use Hugging Face tokenizers \n",
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ad9d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['card', '##iovascular', 'medical', 'records', 'medical', 'records']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pretrained tokenizer (BioBERT)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# Example: tokenize one sample\n",
    "sample_text = nlp_df['cleaned_text'].iloc[0]\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "print(tokens[:30])  # first 30 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696cfdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'input_ids': tensor([[  101,  3621, 25575,  ...,     0,     0,     0],\n",
      "        [  101,  3621, 25575,  ...,     0,     0,     0],\n",
      "        [  101,  3621, 25575,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9468,  1179,  ...,     0,     0,     0],\n",
      "        [  101,  9468,  1179,  ...,     0,     0,     0],\n",
      "        [  101,  9468,  1179,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])})\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and encode all text\n",
    "encodings = tokenizer(\n",
    "    nlp_df['cleaned_text'].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=256,  # adjust based on your GPU\n",
    "    return_tensors=\"pt\"  # PyTorch tensors\n",
    ")\n",
    "\n",
    "print(encodings.keys())  # input_ids, attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17bf4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>admission_dx_count</th>\n",
       "      <th>clinical_notes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141765</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144815</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145427</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientunitstayid  admission_dx_count  clinical_notes_count\n",
       "0             141764                 0.0                   0.0\n",
       "1             141765                 3.0                   2.0\n",
       "2             143870                 4.0                   3.0\n",
       "3             144815                 3.0                   2.0\n",
       "4             145427                 4.0                   2.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged table already has patientunitstayid, admission_dx_count, clinical_notes_count\n",
    "merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dda4618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# Load pretrained BioBERT model\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model.eval()  # set to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Prepare dataset\n",
    "dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "batch_size = 8  # start small, increase if GPU allows\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "152f626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Debug/test run: take only the first 100 rows\n",
    "sample_dataset = torch.utils.data.Subset(dataset, range(1000))\n",
    "sample_loader = torch.utils.data.DataLoader(\n",
    "    sample_dataset, batch_size=4, shuffle=False\n",
    ")\n",
    "\n",
    "all_embeddings = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in sample_loader:\n",
    "        input_ids_batch, attention_mask_batch = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n",
    "        cls_batch = outputs.last_hidden_state[:, 0, :]\n",
    "        all_embeddings.append(cls_batch.cpu())\n",
    "\n",
    "cls_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "print(cls_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2799e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved up to batch 0\n",
      "Saved up to batch 100\n",
      "Saved up to batch 200\n",
      "Saved up to batch 300\n",
      "Saved up to batch 400\n",
      "Saved up to batch 500\n",
      "Saved up to batch 600\n",
      "Saved up to batch 700\n",
      "Saved up to batch 800\n",
      "Saved up to batch 900\n",
      "Saved up to batch 1000\n",
      "Saved up to batch 1100\n",
      "Saved up to batch 1200\n",
      "Saved up to batch 1300\n",
      "Saved up to batch 1400\n",
      "Saved up to batch 1500\n",
      "Saved up to batch 1600\n",
      "Saved up to batch 1700\n",
      "Saved up to batch 1800\n",
      "Saved up to batch 1900\n",
      "Saved up to batch 2000\n",
      "Saved up to batch 2100\n",
      "Saved up to batch 2200\n",
      "Saved up to batch 2300\n",
      "Saved up to batch 2400\n",
      "Saved up to batch 2500\n",
      "Saved up to batch 2600\n",
      "Saved up to batch 2700\n",
      "Saved up to batch 2800\n",
      "Saved up to batch 2900\n",
      "Saved up to batch 3000\n",
      "Saved up to batch 3100\n",
      "Saved up to batch 3200\n",
      "Saved up to batch 3300\n",
      "Saved up to batch 3400\n",
      "Saved up to batch 3500\n",
      "Saved up to batch 3600\n",
      "Saved up to batch 3700\n",
      "Saved up to batch 3800\n",
      "Saved up to batch 3900\n",
      "Saved up to batch 4000\n",
      "Saved up to batch 4100\n",
      "Saved up to batch 4200\n",
      "Saved up to batch 4300\n",
      "Saved up to batch 4400\n",
      "Saved up to batch 4500\n",
      "Saved up to batch 4600\n",
      "Saved up to batch 4700\n",
      "Saved up to batch 4800\n",
      "Saved up to batch 4900\n",
      "Saved up to batch 5000\n",
      "Saved up to batch 5100\n",
      "Saved up to batch 5200\n",
      "Saved up to batch 5300\n",
      "Saved up to batch 5400\n",
      "Saved up to batch 5500\n",
      "Saved up to batch 5600\n",
      "Saved up to batch 5700\n",
      "Saved up to batch 5800\n",
      "Saved up to batch 5900\n",
      "Saved up to batch 6000\n",
      "Saved up to batch 6100\n",
      "Saved up to batch 6200\n",
      "Saved up to batch 6300\n",
      "Saved up to batch 6400\n",
      "Saved up to batch 6500\n",
      "Saved up to batch 6600\n",
      "Saved up to batch 6700\n",
      "Saved up to batch 6800\n",
      "Saved up to batch 6900\n",
      "Saved up to batch 7000\n",
      "Saved up to batch 7100\n",
      "Saved up to batch 7200\n",
      "Saved up to batch 7300\n",
      "Saved up to batch 7400\n",
      "Saved up to batch 7500\n",
      "Saved up to batch 7600\n",
      "Saved up to batch 7700\n",
      "Saved up to batch 7800\n",
      "Saved up to batch 7900\n",
      "Saved up to batch 8000\n",
      "Saved up to batch 8100\n",
      "Saved up to batch 8200\n",
      "Saved up to batch 8300\n",
      "Saved up to batch 8400\n",
      "Saved up to batch 8500\n",
      "Saved up to batch 8600\n",
      "Saved up to batch 8700\n",
      "Saved up to batch 8800\n",
      "Saved up to batch 8900\n",
      "Saved up to batch 9000\n",
      "Saved up to batch 9100\n",
      "Saved up to batch 9200\n",
      "Saved up to batch 9300\n",
      "Saved up to batch 9400\n",
      "Saved up to batch 9500\n",
      "Saved up to batch 9600\n",
      "Saved up to batch 9700\n",
      "Saved up to batch 9800\n",
      "Saved up to batch 9900\n",
      "Saved up to batch 10000\n",
      "Saved up to batch 10100\n",
      "Saved up to batch 10200\n",
      "Saved up to batch 10300\n",
      "Saved up to batch 10400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "save_path = \"embeddings.npy\"\n",
    "all_embeddings = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        input_ids_batch, attention_mask_batch = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n",
    "        cls_batch = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        # Append and periodically save\n",
    "        all_embeddings.append(cls_batch)\n",
    "        if i % 100 == 0:  # every 100 batches\n",
    "            np.save(save_path, np.concatenate(all_embeddings, axis=0))\n",
    "            all_embeddings = []\n",
    "            print(f\"Saved up to batch {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e0b637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 768)\n"
     ]
    }
   ],
   "source": [
    "#  Load Your Embeddings\n",
    "\n",
    "import numpy as np\n",
    "embeddings = np.load(\"embeddings.npy\")  # or however you saved them\n",
    "print(embeddings.shape)  # (num_samples, 768)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151a6ac",
   "metadata": {},
   "source": [
    "“We processed clinical notes, discharge summaries, and drug side effect text with BioBERT/ClinicalBERT, generating high-quality embeddings that can power downstream tasks like retrieval or chatbot answers.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c6c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
